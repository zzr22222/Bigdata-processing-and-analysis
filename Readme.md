**Project Name:** Design and implementation of big data classification algorithms
**Project Goal:** 

Leverage the knowledge gained from this semester's theory and laboratory courses to design a big data classification model based on multi-sample analysis. First, generate a large dataset using a classification data generation program in Python (the size of the data can be set according to the performance of your computer). Then, perform random sample division on the data, with the number of random samples determined by yourself. Next, choose several samples and one (or more) classification algorithms to train multiple models. Finally, design an ensemble rule to integrate the results of multiple models, and use the ensemble model to predict data that was not involved in the training. Record the prediction accuracy, model training time, etc., in the report.

Requirements:

1. When designing the model, you can use the knowledge taught in this semester's theory and laboratory courses, such as data preprocessing, Naive Bayes, K-Nearest Neighbors, Decision Trees, etc., to try to improve the prediction accuracy.
2. Write the assessment report on the "Big Data Processing and Analysis" specific answer sheet, detailing the model design process, key core code (code exceeding 10 lines should be placed in the appendix), experimental results, etc. The more detailed the report, the better. It should be understandable by non-professionals with no related background knowledge.
3. The report should include sections such as an abstract, introduction, model design, experimental results, conclusions, references, etc., and should be no less than 5 pages in length.
4. The report should be well-formatted, with figures (tables) centered, accompanied by captions and relevant analysis in the text. The font should be 'Song' for Chinese and 'Times New Roman' for English, with a font size set to small four. Primary and secondary titles should be bolded.

**Solution:**

I apply a novel big data analysis method that enables big data analysis when the data volume is large (even exceeding available computational resources). This method can approximate the results of the entire dataset using only a few random sample data blocks from a large dataset. The Random Sample Partition (RSP) model divides a large dataset into a group of non-overlapping random sample data blocks. Each block is saved as an RSP data block file, which can be directly used to estimate the statistical properties of the entire dataset. Based on the RSP model, a subset of RSP data blocks is randomly selected, and existing sequential algorithms are used to analyze them in parallel. A progressive ensemble learning framework based on the RSP model (the Alpha framework) is used to address the multi-sample big data classification problem. The final experimental results show that the training accuracy of the classification models based on RSP data blocks is between 78% and 82%. In contrast, the accuracy of the progressive ensemble learning model can exceed 90%. It is evident that using the Alpha computational framework based on RSP progressive ensemble learning can effectively increase the model's accuracy, requiring only a small number of RSP blocks to achieve training accuracy close to that of the original dataset.